# -*- coding: utf-8 -*-
"""Modelo_de_Predição.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xwXQlp5iXDe0INa8N4IZQstQf2FsClF3
"""

# Import the packages
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import yfinance as yf
from keras.models import Sequential
from keras.layers import Dense, LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix
from datetime import datetime as dt
from datetime import timedelta
pd.options.mode.chained_assignment = None

#!pip install tensorflow

acao = "MGLU3.SA"

inicio = "2014-12-31"
final = dt.today().strftime('%Y-%m-%d')

dados_acao = yf.download(acao, inicio, final)

dados_acao

#A Cotação não pode ser ajustada
#Criando um array para trabalhar com Vetores

cotacao = dados_acao['Close'].to_numpy().reshape(-1,1)
cotacao

#Dados de Treino
tamanho_dados_treinamento = int(len(cotacao) * 0.8)

tamanho_dados_treinamento

#Escalar dados entre 0 e 1, para deixar mais facil processamento
#dados em escala pré definidos são mais faceis de usar

escalador = MinMaxScaler(feature_range=(0,1))

dados_entre_0_e_1_treinamento = escalador.fit_transform(cotacao[0: tamanho_dados_treinamento, :])

dados_entre_0_e_1_teste = escalador.fit_transform(cotacao[tamanho_dados_treinamento:, :])

dados_entre_0_e_1 = list(dados_entre_0_e_1_treinamento.reshape(
    len(dados_entre_0_e_1_treinamento))) + list(dados_entre_0_e_1_teste.reshape(len(dados_entre_0_e_1_teste)))

dados_entre_0_e_1 = np.array(dados_entre_0_e_1).reshape(len(dados_entre_0_e_1), 1)

dados_entre_0_e_1

#
dados_para_treinamento = dados_entre_0_e_1[0: tamanho_dados_treinamento, :]

#dados que serão usados para gerar resultado
treinamento_x = []
#cotação que aconteceu de fato
treinamento_y = []

for i in range(60, len(dados_para_treinamento)):

    #60 ultimos dias
    treinamento_x.append(dados_para_treinamento[i-60:i, 0])
    #cotação
    treinamento_y.append(dados_para_treinamento[i, 0])

    if i <= 61:

        print(treinamento_x)
        print(treinamento_y)

#transformando as listas em arrays e dando reshape 3d

treinamento_x, treinamento_y = np.array(treinamento_x), np.array(treinamento_y)

print(treinamento_x)

treinamento_x = np.reshape(treinamento_x, (treinamento_x.shape[0], treinamento_x.shape[1], 1))

print(treinamento_x)

#construindo o modelo

modelo = Sequential()

#criar um modelo com 50 neurônios
#return sequence = True pois vai usar mais LSTM(Long Short Term Memory)
#definir o shape, que no caso são informações para gerar uma.
#adicionar mais neurônios com o dense, 25 e 1
#Arquitetura de Deep Learning

modelo.add(LSTM(units=50, return_sequences=True, input_shape=(treinamento_x.shape[1], 1)))
modelo.add(LSTM(units=50, return_sequences=False))
modelo.add(Dense(units=25))
modelo.add(Dense(units=1))

treinamento_x.shape[1]

#copilando o modelo

#a função do loss é medir o erro do modelo, que nesse caso
#é o erro médio quadratico que é usado em regressão linear
#otimizar a medida de erro

modelo.compile(optimizer='adam', loss='mean_squared_error')

#agora com o modelo copilado e os dados
#começa o treinamento do modelo
#butch size é depois de quantas em quantas amostras o modelo irá otimizar os parametros
#epoch é quantas vezes o modelo irá rodar os dados aprendendo

modelo.fit(treinamento_x, treinamento_y,batch_size=10, epochs=50)

#criar os dados de teste

dados_teste = dados_entre_0_e_1[tamanho_dados_treinamento - 60: , :]

teste_x = []
teste_y = cotacao[tamanho_dados_treinamento:, :]

for i in range(60, len(dados_teste)):
  teste_x.append(dados_teste[i-60:i, 0])

#reshape
teste_x = np.array(teste_x)
teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)

#pegando predições do modelo

predicoes = modelo.predict(teste_x)

#tirando a escala dos dados

predicoes = escalador.inverse_transform(predicoes)

predicoes

#pegando o erro medio quadratico (RMSE)

rmse = np.sqrt(np.mean(predicoes - teste_y) ** 2)
rmse

#criando o grafico do modelo

treinamento = dados_acao.iloc[: tamanho_dados_treinamento, :]
df_teste = pd.DataFrame({"Close" : dados_acao['Close'].iloc[tamanho_dados_treinamento:],
                         "predicoes":predicoes.reshape(len(predicoes))})

plt.figure(figsize = (16,8))
plt.title('Modelo')
plt.xlabel('Data', fontsize=18)
plt.ylabel('Preço de fechamento', fontsize=18)
plt.plot(treinamento['Close'])
plt.plot(df_teste[['Close', 'predicoes']])
plt.legend(['Treinamento', 'Real', 'Predicoes'], loc=2, prop={'size':16})
plt.show()

df_teste.sort_index()
df_teste

#calcular media de acertos e lucro

df_teste['variacao_percentual_acao'] = df_teste['Close'].pct_change()
df_teste['variacao_percentual_modelo'] = df_teste['predicoes'].pct_change()

df_teste = df_teste.dropna()

df_teste['var_acao_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_acao'] > 0,
                                               True, False)
df_teste['var_modelo_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_modelo'] > 0,
                                               True, False)

df_teste['acertou_o_lado'] = np.where(df_teste['var_acao_maior_menor_que_zero'] == df_teste['var_modelo_maior_menor_que_zero'] ,
                                      True, False)

df_teste['variacao_percentual_acao_abs'] = df_teste['variacao_percentual_acao'].abs()

df_teste

acertou_lado = df_teste['acertou_o_lado'].sum()/len(df_teste['acertou_o_lado'])
errou_lado = 1 - acertou_lado

media_lucro = df_teste.groupby('acertou_o_lado')['variacao_percentual_acao_abs'].mean()

exp_mat_lucro = acertou_lado * media_lucro[1] - media_lucro[0] * errou_lado

ganho_sobre_perda = media_lucro[1] / media_lucro[0]

print(media_lucro)
print(ganho_sobre_perda)
print(acertou_lado)
print(exp_mat_lucro * 100)

#descobrindo o preco de hoje/amanhã com esse modelo

data_hoje = dt.now()

#se quiser escolher um dia (substitua o valor de days)
#data_hoje = dt.now() - timedelta(days=1)

if data_hoje.hour > 18:
  final = data_hoje
  inicial = dt.now() - timedelta(days=252)

else:
  final = data_hoje - timedelta(days=1)
  inicial = dt.now() - timedelta(days=252)

cotacoes = yf.download(acao, inicio, final)
ultimos_60_dias = cotacoes['Close'].iloc[-60:].values.reshape(-1,1)

ultimos_60_dias_escalado = escalador.transform(ultimos_60_dias)

teste_x = []
teste_x.append(ultimos_60_dias_escalado)
teste_x = np.array(teste_x)
teste_x = np.reshape(teste_x, (teste_x.shape[0], teste_x.shape[1], 1))

previsao_de_preco = modelo.predict(teste_x)

previsao_de_preco= escalador.inverse_transform(previsao_de_preco)

print(previsao_de_preco)